{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from texttransformation import StringTransform, RowTextTransform, TransformDataset\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alter dataset by injecting various random errors, typos etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "alteration_rules = [\n",
    "    {\n",
    "        'rule_Replace': ['none',''],\n",
    "        'rule_RandomTypo': ['alpha', 2, 'replace'],\n",
    "        'rule_ScrambleWords': [],\n",
    "        'rule_DuplicateNumericSequence': [2],\n",
    "        'rule_RemoveSpecialSymbols': [],\n",
    "        'rule_RemoveStopWords': [],\n",
    "        'rule_IncreaseWeightOfShortWords':[]\n",
    "    },\n",
    "    {\n",
    "        'rule_Replace': ['none',''],\n",
    "        'rule_RandomTypo': ['any', 2, 'add'],\n",
    "        'rule_ScrambleWords': [],\n",
    "        'rule_DuplicateNumericSequence': [4],\n",
    "        'rule_RemoveSpecialSymbols': [],\n",
    "        'rule_RemoveStopWords': [],\n",
    "        'rule_IncreaseWeightOfShortWords':[]\n",
    "    },\n",
    "    {\n",
    "        'rule_Replace': ['none',''],\n",
    "        'rule_RandomTypo': ['digits', 1, 'add'],\n",
    "        'rule_ScrambleWords': [],\n",
    "        'rule_DuplicateNumericSequence': [3],\n",
    "        'rule_RemoveSpecialSymbols': [],\n",
    "        'rule_RemoveStopWords': [],\n",
    "        'rule_IncreaseWeightOfShortWords':[]\n",
    "    }\n",
    "]\n",
    "\n",
    "column_alteration_rules = []\n",
    "for i in range(0, len(alteration_rules)):\n",
    "    column_alteration_rules.append(\n",
    "        {\n",
    "            1: alteration_rules[i],\n",
    "            2: alteration_rules[i],                    \n",
    "            3: alteration_rules[i],\n",
    "            4: alteration_rules[i],\n",
    "            5: alteration_rules[i],\n",
    "            6: alteration_rules[i],\n",
    "            7: alteration_rules[i],\n",
    "            8: alteration_rules[i],\n",
    "            9: alteration_rules[i]\n",
    "        })\n",
    "\n",
    "result = []\n",
    "for rule in range(0, len(alteration_rules)):\n",
    "    transformer = TransformDataset(column_alteration_rules[rule])    \n",
    "    result = result + transformer.execute(df_source.values.tolist())\n",
    "\n",
    "df_source_alterd  = pd.DataFrame(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
